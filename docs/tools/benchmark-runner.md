# VelinScript Benchmark Runner

Der Benchmark Runner f√ºhrt Performance-Benchmarks aus mit statistischer Auswertung.

## Installation

Das Tool ist Teil der VelinScript Toolchain. Baue es mit:

```bash
cd tools/benchmark-runner
cargo build --release
```

## Verwendung

### Benchmarks ausf√ºhren

```bash
velin-bench run
```

F√ºhrt alle Benchmarks im aktuellen Verzeichnis aus.

### Spezifische Datei benchmarken

```bash
velin-bench run path/to/benchmark.velin
```

### Anzahl Iterationen

```bash
velin-bench run --iterations 1000
```

### Mit Vergleich

```bash
velin-bench run --compare
```

Vergleicht Ergebnisse mit vorherigen Runs.

### Output speichern

```bash
velin-bench run --output results.json
```

### Verbose Output

```bash
velin-bench run --verbose
```

## Features

### @benchmark Annotationen

Benchmarks werden mit `@benchmark` Decorator markiert:

```velin
@benchmark
fn benchmarkSort() {
    let data = generateLargeArray(10000);
    sort(data);
}

@benchmark
fn benchmarkSearch() {
    let data = generateLargeArray(10000);
    search(data, 5000);
}
```

### Statistische Auswertung

Der Benchmark Runner berechnet:

- **Mittelwert** - Durchschnittliche Ausf√ºhrungszeit
- **Minimum** - Schnellste Ausf√ºhrung
- **Maximum** - Langsamste Ausf√ºhrung
- **Standardabweichung** - Streuung der Ergebnisse

## Beispiel-Output

```
‚ö° F√ºhre Benchmarks aus...

üîç Benchmarke: benchmarks/sort.velin

üìä Benchmark-Ergebnisse:
  benchmarkSort: 12.45ms (100 Iterationen)
    Min: 11.23ms, Max: 14.67ms, StdDev: 0.89ms
  benchmarkSearch: 8.32ms (100 Iterationen)
    Min: 7.91ms, Max: 9.12ms, StdDev: 0.34ms
```

## JSON-Format

```json
[
  {
    "name": "benchmarkSort",
    "mean_time": 12.45,
    "min_time": 11.23,
    "max_time": 14.67,
    "std_dev": 0.89,
    "iterations": 100
  }
]
```

## Integration

### CI/CD

```yaml
# .github/workflows/benchmark.yml
- name: Run Benchmarks
  run: |
    cd tools/benchmark-runner
    cargo build --release
    ./target/release/velin-bench run --output benchmark.json
```

## Best Practices

1. **Ausreichend Iterationen** - Nutze mindestens 100 Iterationen
2. **Warme L√§ufe** - Ignoriere erste Iterationen (Warmup)
3. **Konsistente Umgebung** - F√ºhre Benchmarks unter gleichen Bedingungen aus
4. **Regelm√§√üige Benchmarks** - √úberwache Performance im Zeitverlauf

## Troubleshooting

### Benchmarks sind zu langsam

- Reduziere Anzahl Iterationen
- Pr√ºfe System-Last
- Nutze Release-Builds

### Ungenaue Ergebnisse

- Erh√∂he Anzahl Iterationen
- F√ºhre Benchmarks mehrfach aus
- Pr√ºfe auf Hintergrund-Prozesse

## Weitere Ressourcen

- [Tools √úbersicht](TOOLS_√úBERSICHT.md)
- [Wann nutze ich was?](../wann-nutze-ich-was.md)
- [Profiler](profiler.md)

---

**Letzte Aktualisierung:** 2026-01-30  
**Version:** 0.1.0
